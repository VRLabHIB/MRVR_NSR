install.packages("emmeans")
install.packages("tidyselect")
install.packages("ARTool")
install.packages("apaTables")
install.packages("lsr")
install.packages("genefilter")
library(ARTool)
library(emmeans)
library(apaTables)
library(lsr)
mydata = read.csv("C:/Users/Stark/OneDrive - UT Cloud/Documents/Master_Kognition/4_Semester_2020_SS/2020_Masterarbeit/data/OOI_time_data/stud05.csv")
print('student')
m <- art(stud ~ hand*sitting*cartoon, data=mydata)
anova(m)
emmeans(artlm(m, "hand"), pairwise ~ hand)
mydata = read.csv("C:/Users/Stark/OneDrive - UT Cloud/Documents/Master_Kognition/4_Semester_2020_SS/2020_Masterarbeit/data/OOI_time_data/teacher05.csv")
print('Teacher')
m <- art(teacher ~ hand*sitting*cartoon, data=mydata)
anova(m)
emmeans(artlm(m, "hand"), pairwise ~ hand)
mydata = read.csv("C:/Users/Stark/OneDrive - UT Cloud/Documents/Master_Kognition/4_Semester_2020_SS/2020_Masterarbeit/data/OOI_time_data/screen05.csv")
print('Screen')
m <- art(screen ~ hand*sitting*cartoon, data=mydata)
anova(m)
emmeans(artlm(m, "hand"), pairwise ~ hand)
View(mydata)
library(ARTool)
library(emmeans)
library(apaTables)
library(lsr)
mydata = read.csv("C:/Users/Stark/OneDrive - UT Cloud/Documents/Master_Kognition/4_Semester_2020_SS/2020_Masterarbeit/data/OOI_time_data/stud05.csv")
print('student')
mydata$sitting <- as.character(mydata$sitting)
mydata$sitting[mydata$sitting == "front"] <- 0
mydata$sitting[mydata$sitting == "back"] <- 1
mydata$sitting <- as.factor(mydata$sitting)
View(mydata)
mydata$cartoon <- as.character(mydata$cartoon)
mydata$cartoon[mydata$cartoon == "cartoon"] <- 0
mydata$cartoon[mydata$cartoon == "real"] <- 1
mydata$cartoon <- as.factor(mydata$cartoon)
m <- art(stud ~ hand*sitting*cartoon, data=mydata)
anova(m)
emmeans(artlm(m, "hand"), pairwise ~ hand)
q()
rm(list=ls())
cat("\014")
#install.packages('installr')
library('installr')
#install.packages('psych')
library('psych')
#install.packages('corrplot')
library('corrplot')
#install.packages('dplyr')
library('dplyr')
#install.packages('car')
library('car')
#install.packages('data.table')
library('data.table')
#install.packages('readr')
library('readr')
install.packages('apaTables')
library('apaTables')
#install.packages('ggplot2')
library('ggplot2')
#install.packages('flextable')
library('flextable')
#install.packages('tidyr')
library('tidyr')
#Datensatz einlesen
setwd('C:\\Users\\Stark\\OneDrive - UT Cloud\\Teaching\\2023_22_Computergestützte_Datenanalyse\\Seminarleistung')
dat <- read.csv2("VR_experiment.csv", sep = ";")
View(dat)
#Fehlende Werte sind mir "-99" gekennzeichnet
sum(dat == -99) #Es gibt 157 fehlende Werte im Datenatz
#Datensatz von fehlenden Werten reinigen
dat[dat == -99] <- NA #Fehlende Werte als NA kodieren, damit die Bearbeitung mit R einfacher wird
dat_1 <- dat[complete.cases(dat),]
sum(is.na(dat_1))
#Es gibt keine "NA"s bzw. fehlenden Werte mehr in dat_1
#negative Items umkodieren
#inversive Items: ski01, ski04, ski05, ski08
dat_1$sksi01<- recode(dat_1$sksi01, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi04<- recode(dat_1$sksi04, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi05<- recode(dat_1$sksi05, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi08<- recode(dat_1$sksi08, "1=4; 2=3 ; 3=2 ; 4=1")
#Mit der Recode-Funktion wurden alle Items rekodiert, sodass alle hohen Werte auch für ein hohes Selbstkonzept stehen
library('Hmisc')
#Verwende ursprünglichen Datensatz:
dat$sksi01<- recode(dat$sksi01, "1=4; 2=3 ; 3=2 ; 4=1")
dat$sksi04<- recode(dat$sksi04, "1=4; 2=3 ; 3=2 ; 4=1")
dat$sksi05<- recode(dat$sksi05, "1=4; 2=3 ; 3=2 ; 4=1")
dat$sksi08<- recode(dat$sksi08, "1=4; 2=3 ; 3=2 ; 4=1")
dat.i_1 <- impute(dat, mean)
dat.i_2 <- impute(dat)
dat.i <- impute(dat, "random")
#"mean" Funktion: alle NA's werden durch den Mittelwert (3.486) ersetzt
#default (median) durch den Median (4)
#"random" Funktion: Werte werden randomisiert
#Testen, welches Item die meisten NA's aufweist
sum(is.na(dat$sksi01)) #3
sum(is.na(dat$sksi02)) #4
sum(is.na(dat$sksi03)) #4
sum(is.na(dat$sksi04)) #47
sum(is.na(dat$sksi05)) #45
sum(is.na(dat$sksi06)) #4
sum(is.na(dat$sksi07)) #4
sum(is.na(dat$sksi08)) #46
#ski04 hat die meisten NA's
#grafissche Darstellung der Verteilungshäufigkeit der Antworten auf ski04
hist(dat_1$sksi04)
hist(dat.i$sksi04)
hist(dat.i_1$sksi04)
hist(dat.i_2$sksi04)
library('lavaan')
#Konfirmatorische Faktorenanalyse (CFA)
names(dat_1)
model1 <- 'gsk = ~sksi01 + sksi02 + sksi03 + sksi04 + sksi05 + sksi06 + sksi07 + sksi08'
SK <- cfa(model1, data=dat_1)
summary(SK)
summary(SK, standardized=TRUE, fit.measures=TRUE)
library('semPlot')
semPaths(SK, what = "par", weighted = FALSE)
unlink("C:/Users/Stark/OneDrive - UT Cloud/Teaching/2023_22_Computergestützte_Datenanalyse/Abgaben/Siebert_Ines_i.siebert_4012603/Einsendeaufgabe_Siebert_cache", recursive = TRUE)
c <- cor(dat_1)
print(c)
c.i <- cor(dat.i)
print(c.i)
#Visualisierung der Daten
corrplot(cor(dat_1), method="number", type="lower", diag = FALSE)
corrplot(cor(dat.i), method="number", type="lower", diag = FALSE)
#Weiterarbeiten mit dem reduzierten Datensatz dat_1
testRes = cor.mtest(dat_1, conf.level = 0.95)
corrplot(c, p.mat = testRes$p, method="number", type="lower", diag = FALSE, sig.level = 0.05,insig = 'label_sig', pch.cex = 0.9)
#Mittelwerte:
des<- describe(dat_1)
sum <- summary(dat_1)
mean <- c(mean(dat_1$sksi01),mean(dat_1$sksi02), mean(dat_1$sksi03), mean(dat_1$sksi04), mean(dat_1$sksi05), mean(dat_1$sksi06), mean(dat_1$sksi07), mean(dat_1$sksi08))
sd <- c(sd(dat_1$sksi01), sd(dat_1$sksi02), sd(dat_1$sksi03), sd(dat_1$sksi04), sd(dat_1$sksi05), sd(dat_1$sksi06), sd(dat_1$sksi07), sd(dat_1$sksi08))
mean_sd <- data.frame(mean,sd, row.names = 1:8)
#Gesamter Mittelwert: mean(mean_sd$mean)
#Gesamte Standardabweichung:mean(mean_sd$sd)
mean_final <- c(mean(dat_1$sksi01),mean(dat_1$sksi02), mean(dat_1$sksi03), mean(dat_1$sksi04), mean(dat_1$sksi05), mean(dat_1$sksi06), mean(dat_1$sksi07), mean(dat_1$sksi08), mean(mean_sd$mean))
sd_final <- c(sd(dat_1$sksi01), sd(dat_1$sksi02), sd(dat_1$sksi03), sd(dat_1$sksi04), sd(dat_1$sksi05), sd(dat_1$sksi06), sd(dat_1$sksi07), sd(dat_1$sksi08), mean(mean_sd$sd))
mean_sd_final <- data.frame(mean_final,sd_final, row.names = c("1","2","3","4","5","6","7","8", "Gesamt"))
print(mean_sd_final)
#Berechnung der internen Konsistenz mithilfe des Cronbachs Alpha
psych::alpha(dat_1)
#alpha= 0,849, Konfidezintervall von [0,82;0,87]
#Überfpüfung mit der split-half Reliabilität
splitHalf(dat_1)
#Erstellen der Subdatensätze dat_s (mit sozialem Vergleich) und dat_k (kriteriale Fragen)
dat_s <- dat_1[, c(1:4)]
dat_k <- dat_1[, c(5:8)]
#Berechnung der Reiabilität
splitHalf(dat_s)
#max= 0,78; min= 0,64; average slpit half= 0,72; a=0,72
psych::alpha(dat_s)
#a= 0,71, ci= [0,65;0,76]
splitHalf(dat_k)
#max= 0,81; min= 0,75; average slpit half= 0,78; a=0,78
psych::alpha(dat_k)
#a= 0,77, ci= [0,73;0,81]
library('lavaan')
#Konfirmatorische Faktorenanalyse (CFA)
names(dat_1)
model1 <- 'gsk = ~sksi01 + sksi02 + sksi03 + sksi04 + sksi05 + sksi06 + sksi07 + sksi08'
SK <- cfa(model1, data=dat_1)
summary(SK)
summary(SK, standardized=TRUE, fit.measures=TRUE)
library('semPlot')
semPaths(SK, what = "par", weighted = FALSE)
#mit soz. Vergleichen
model2 <- 'ssk = ~sksi01 + sksi02 + sksi03 + sksi04'
SSK <- cfa(model2, data=dat_s)
summary(SSK, standardized=TRUE, fit.measures=TRUE)
#kriterial
model3 <- 'ksk = ~sksi05 + sksi06 + sksi07 + sksi08'
KSK <- cfa(model3, data=dat_k)
summary(KSK, standardized=TRUE, fit.measures=TRUE)
semPaths(SK, what = "par", weighted = FALSE)
semPaths(SSK, what = "par", weighted = FALSE)
semPaths(KSK, what = "par", weighted = FALSE)
#Datensatz einlesen
setwd('C:\\Users\\Stark\\OneDrive - UT Cloud\\Teaching\\2023_22_Computergestützte_Datenanalyse\\Seminarleistung')
dat <- read.csv2("VR_experiment.csv", sep = ";")
View(dat)
#Fehlende Werte sind mir "-99" gekennzeichnet
sum(dat == -99) #Es gibt 157 fehlende Werte im Datenatz
#Datensatz von fehlenden Werten reinigen
dat[dat == -99] <- NA #Fehlende Werte als NA kodieren, damit die Bearbeitung mit R einfacher wird
dat_1 <- dat[complete.cases(dat),]
sum(is.na(dat_1))
#Es gibt keine "NA"s bzw. fehlenden Werte mehr in dat_1
#negative Items umkodieren
#inversive Items: ski01, ski04, ski05, ski08
dat_1$sksi01<- recode(dat_1$sksi01, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi04<- recode(dat_1$sksi04, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi05<- recode(dat_1$sksi05, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi08<- recode(dat_1$sksi08, "1=4; 2=3 ; 3=2 ; 4=1")
#Mit der Recode-Funktion wurden alle Items rekodiert, sodass alle hohen Werte auch für ein hohes Selbstkonzept stehen
#Datensatz einlesen
setwd('C:\\Users\\Stark\\OneDrive - UT Cloud\\Teaching\\2023_22_Computergestützte_Datenanalyse\\Seminarleistung')
dat <- read.csv2("VR_experiment.csv", sep = ";")
#Fehlende Werte sind mir "-99" gekennzeichnet
sum(dat == -99) #Es gibt 157 fehlende Werte im Datenatz
#Datensatz von fehlenden Werten reinigen
dat[dat == -99] <- NA #Fehlende Werte als NA kodieren, damit die Bearbeitung mit R einfacher wird
dat_1 <- dat[complete.cases(dat),]
sum(is.na(dat_1))
#Es gibt keine "NA"s bzw. fehlenden Werte mehr in dat_1
#negative Items umkodieren
#inversive Items: ski01, ski04, ski05, ski08
dat_1$sksi01<- recode(dat_1$sksi01, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi04<- recode(dat_1$sksi04, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi05<- recode(dat_1$sksi05, "1=4; 2=3 ; 3=2 ; 4=1")
dat_1$sksi08<- recode(dat_1$sksi08, "1=4; 2=3 ; 3=2 ; 4=1")
#Mit der Recode-Funktion wurden alle Items rekodiert, sodass alle hohen Werte auch für ein hohes Selbstkonzept stehen
# Code kann hier eingefügt werden...
x <- 1+1
print(x)
library(psych)
library(corrplot)
library(ggplot2)
install.packages("nFactors")
library(nFactors)
setwd('C:\\Users\\Stark\\OneDrive - UT Cloud\\Teaching\\2023_22_Computergestützte_Datenanalyse\\Seminarleistung')
VR_experiment <- read.csv2("VR_experiment.csv", na.strings = c(-99,"NA" ))
sapply(VR_experiment, anyNA)
library(psych)
library(corrplot)
library(ggplot2)
# install.packages("nFactors")
library(nFactors)
setwd('C:\\Users\\Stark\\OneDrive - UT Cloud\\Teaching\\2023_22_Computergestützte_Datenanalyse\\Seminarleistung')
VR_experiment <- read.csv2("VR_experiment.csv", na.strings = c(-99,"NA" ))
sapply(VR_experiment, anyNA)
#Subdatensatz ohne fehlende Werte:
VR_experiment_clean <- na.omit(VR_experiment)
install.packages(car)
library(car)
#Datensatz umcodieren
VR_experiment_clean$sksi01 <- recode(VR_experiment_clean$sksi01, "1=4; 2=3; 3=2; 4=1")
VR_experiment_clean$sksi04 <- recode(VR_experiment_clean$sksi04, "1=4; 2=3; 3=2; 4=1")
VR_experiment_clean$sksi05 <- recode(VR_experiment_clean$sksi05, "1=4; 2=3; 3=2; 4=1")
VR_experiment_clean$sksi08 <- recode(VR_experiment_clean$sksi08, "1=4; 2=3; 3=2; 4=1")
#Subdatensatz ohne fehlende Werte:
VR_experiment_clean <- na.omit(VR_experiment)
# install.packages(car)
library(car)
#Datensatz umcodieren
VR_experiment_clean$sksi01 <- recode(VR_experiment_clean$sksi01, "1=4; 2=3; 3=2; 4=1")
VR_experiment_clean$sksi04 <- recode(VR_experiment_clean$sksi04, "1=4; 2=3; 3=2; 4=1")
VR_experiment_clean$sksi05 <- recode(VR_experiment_clean$sksi05, "1=4; 2=3; 3=2; 4=1")
VR_experiment_clean$sksi08 <- recode(VR_experiment_clean$sksi08, "1=4; 2=3; 3=2; 4=1")
print(VR_experiment_clean)
sapply(VR_experiment_clean, anyNA)
#install.packages(Hmisc)
library(Hmisc)
VR_experiment$imputed_sksi02 <- with(VR_experiment, impute(sksi02, mean))
#install.packages(Hmisc)
library(Hmisc)
VR_experiment$imputed_sksi02 <- with(VR_experiment, impute(sksi02, mean))
#install.packages(Hmisc)
# library(Hmisc)
VR_experiment$imputed_sksi02 <- with(VR_experiment, impute(sksi02, mean))
#install.packages(Hmisc)
# library(Hmisc)
#VR_experiment$imputed_sksi02 <- with(VR_experiment, impute(sksi02, mean))
#VR_experiment$imputed_sksi03 <- with(VR_experiment, impute(sksi03, mean))
#VR_experiment$imputed_sksi04 <- with(VR_experiment, impute(sksi04, mean))
#VR_experiment$imputed_sksi05 <- with(VR_experiment, impute(sksi05, mean))
#VR_experiment$imputed_sksi06 <- with(VR_experiment, impute(sksi06, mean))
#VR_experiment$imputed_sksi01 <- with(VR_experiment, impute(sksi01, mean))
c_v <- cor (VR_experiment_clean)
print(c_v)
#Interpretation: Die größte Korrelation zweier Items beträgt 0.6393745, was bedeutet dass die beiden Items sksi05  (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht)und sksi04 (Es fiel mir schwerer als den anderen Schülerinnen und Schülern die Roboteraufgaben zu verstehen) mittelstark positiv miteinader korrelieren. Das bedeutet, dass Schüler*innen, die denken, die  Aufgaben weniger gut verstanden zu haben als andere, auch weniger mit ihnen zurecht kamen. Hier gibt es also einen positiven Zusammenhang zwischen dem sozialen Vergleich und dem kriterialen. Den geringsten Zusammhang findet man mit 0.3019834 zwischen sksi05 (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht) und sksi02 (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht). Es besteht immer noch eine leichte positivie Korrelation. Es gibt keine negativen Korrelationen, was bedeutet dass die Items alle mindestens gering positiv miteinader korrelieren.
## Kür
#install.packages(corrplot)
corrplot(cor)
c_v <- cor (VR_experiment_clean)
print(c_v)
#Interpretation: Die größte Korrelation zweier Items beträgt 0.6393745, was bedeutet dass die beiden Items sksi05  (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht)und sksi04 (Es fiel mir schwerer als den anderen Schülerinnen und Schülern die Roboteraufgaben zu verstehen) mittelstark positiv miteinader korrelieren. Das bedeutet, dass Schüler*innen, die denken, die  Aufgaben weniger gut verstanden zu haben als andere, auch weniger mit ihnen zurecht kamen. Hier gibt es also einen positiven Zusammenhang zwischen dem sozialen Vergleich und dem kriterialen. Den geringsten Zusammhang findet man mit 0.3019834 zwischen sksi05 (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht) und sksi02 (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht). Es besteht immer noch eine leichte positivie Korrelation. Es gibt keine negativen Korrelationen, was bedeutet dass die Items alle mindestens gering positiv miteinader korrelieren.
## Kür
#install.packages(corrplot)
corrplot(data.frame(cor))
c_v <- cor(VR_experiment_clean)
print(c_v)
#Interpretation: Die größte Korrelation zweier Items beträgt 0.6393745, was bedeutet dass die beiden Items sksi05  (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht)und sksi04 (Es fiel mir schwerer als den anderen Schülerinnen und Schülern die Roboteraufgaben zu verstehen) mittelstark positiv miteinader korrelieren. Das bedeutet, dass Schüler*innen, die denken, die  Aufgaben weniger gut verstanden zu haben als andere, auch weniger mit ihnen zurecht kamen. Hier gibt es also einen positiven Zusammenhang zwischen dem sozialen Vergleich und dem kriterialen. Den geringsten Zusammhang findet man mit 0.3019834 zwischen sksi05 (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht) und sksi02 (Ich kam mit den Roboter-Aufgaben nicht so gut zurecht). Es besteht immer noch eine leichte positivie Korrelation. Es gibt keine negativen Korrelationen, was bedeutet dass die Items alle mindestens gering positiv miteinader korrelieren.
## Kür
#install.packages(corrplot)
corrplot(cor)
setwd('C:\\Users\\Stark\\Documents\\Promotion\\_Mental_Rotation\\03_MR_in_VR\\MRVR_NSR\\data\\5_feature_dataset\\')
df <- read.csv2('features.csv',sep = ',')
View(df)
View(df)
t.test(df['2DRT'], df['3DRT'], paired = TRUE, alternative = "two.sided")
View(df)
t.test(df['X2DRT'], df['X3DRT'], paired = TRUE, alternative = "two.sided")
View(df)
df.columns
df.columns()
colnames(df)
t.test(df[:,"X2DRT"], df[:,"X3DRT"], paired = TRUE, alternative = "two.sided")
df <- read.csv2('features.csv',header = TRUE,  = ',',  dec = ".")
View(df)
df["X2DRT"]
t.test(df["X2DRT"], df["X3DRT"], paired = TRUE, alternative = "two.sided")
df["X3DRT"]
df["X3DRT"]
x <-df["X2DRT"]
x <-ls(df["X2DRT"])
t.test( df$X2DRT,df$X3DRT, paired = TRUE, alternative = "two.sided")
df$X2DRT <- as.numeric(df$X2DRT)
df$X3DRT <- as.numeric(df$X3DRT)
t.test( df$X2DRT,df$X3DRT, paired = TRUE, alternative = "two.sided")
df$X2DCorrect <- as.numeric(df$X2DCorrect)
df$X3DCorrect <- as.numeric(df$X3DCorrect)
t.test( df$X2DCorrect,df$X3DCorrect, paired = TRUE, alternative = "two.sided")
df.summary()
summary(df)
